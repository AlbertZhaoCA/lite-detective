# LiteDetective

A lightweight Chinese malicious comment detection pipeline.

è½»é‡çº§ä¸­æ–‡æœ‰å®³è¯„è®ºæ£€æµ‹å·¥å…·ã€‚

---

## Features / åŠŸèƒ½ç®€ä»‹
- Model training and evaluation for toxic comment detection
- Data processing and policy generation
- Console entry points for quick data and policy generation

- æœ‰å®³è¯„è®ºæ£€æµ‹æ¨¡å‹è®­ç»ƒä¸è¯„æµ‹
- æ•°æ®å¤„ç†ä¸ç­–ç•¥ç”Ÿæˆ
- å‘½ä»¤è¡Œå…¥å£ï¼Œä¾¿æ·ç”Ÿæˆç­–ç•¥å’Œè®­ç»ƒæ•°æ®

---

## Quick Start / å¿«é€Ÿå¼€å§‹

### 1. Install dependencies / å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### 2. Data Preparation / æ•°æ®å‡†å¤‡
- Place your training and test data in the `data/` directory. See `data/` for format examples.
- å°†è®­ç»ƒå’Œæµ‹è¯•æ•°æ®æ”¾å…¥ `data/` ç›®å½•ï¼Œæ ¼å¼å¯å‚è€ƒå·²æœ‰æ–‡ä»¶ã€‚

### 3. Train the model / è®­ç»ƒæ¨¡å‹
```bash
python train.py
```

### 4. Test the model / æµ‹è¯•æ¨¡å‹
```bash
python test.py
```

---

## Console Entrypoints / å‘½ä»¤è¡Œå…¥å£

After installation (or in project root):
å®‰è£…åï¼ˆæˆ–åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼‰ï¼š

- Generate policy file / ç”Ÿæˆç­–ç•¥æ–‡ä»¶ï¼š
```bash
build-policy --path data/raw --policy_file data/policy.jsonl
```
- Generate training data / ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼š
```bash
build-train-data --policy_file data/policy.jsonl --output_file data/training_data.jsonl
```

---

## Installation (with setup.py) / å®‰è£…ï¼ˆä½¿ç”¨ setup.pyï¼‰

You can install LiteDetective as a Python package, which will also enable the command line tools:

ä½ å¯ä»¥é€šè¿‡ setup.py å®‰è£…æœ¬é¡¹ç›®ä¸º Python åŒ…ï¼Œå¹¶è‡ªåŠ¨è·å¾—å‘½ä»¤è¡Œå·¥å…·ï¼š

```bash
pip install -e .
```

After installation, you can use the following commands anywhere:
å®‰è£…åï¼Œå¯åœ¨ä»»æ„ä½ç½®ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š

- `build-policy`  â€”â€”  Generate policy file / ç”Ÿæˆç­–ç•¥æ–‡ä»¶
- `build-train-data`  â€”â€”  Generate training data / ç”Ÿæˆè®­ç»ƒæ•°æ®

---

## Project Structure / é¡¹ç›®ç»“æ„
- `train.py`, `test.py`: Model training/testing
- `libs/`: Data processing, policy, LLM SDK, etc.
- `models/`: Model definitions
- `data/`: Datasets and generated files

- `train.py`, `test.py`ï¼šæ¨¡å‹è®­ç»ƒä¸æµ‹è¯•
- `libs/`ï¼šæ•°æ®å¤„ç†ã€ç­–ç•¥ã€LLM SDK ç­‰
- `models/`ï¼šæ¨¡å‹ç»“æ„
- `data/`ï¼šæ•°æ®é›†ä¸ç”Ÿæˆæ–‡ä»¶

---

## License / è®¸å¯è¯
MIT License

---

## ä½¿ç”¨ predict å‡½æ•°è¿›è¡Œæ¨ç† / How to use the predict function

### 1. ä¸‹è½½æ¨¡å‹æƒé‡ (download the model weight file)
è¯·ä» [HuggingFace: Albert-CAC/lite_DETECTIVE](https://huggingface.co/Albert-CAC/lite_DETECTIVE/tree/main) ä¸‹è½½ `lited_best.pth` æ–‡ä»¶ï¼Œæ”¾åˆ°æœ¬åœ°ç›®å½•ï¼ˆå¦‚ `./hf_ckpt/`ï¼‰ã€‚

### 2. åŠ è½½æ¨¡å‹ä¸æƒé‡ (load the model)
```python
import torch
from models.classifier import ToxicTextClassifier

model = ToxicTextClassifier()
state_dict = torch.load('hf_ckpt/lited_best.pth', map_location='cpu')
model.load_state_dict(state_dict)
model.eval()
```

### 3. ä½¿ç”¨ predict è¿›è¡Œæ¨ç† (how to inference)
#### å•æ¡æ–‡æœ¬ (without context)
```python
result = model.predict('ä½ çœŸè®¨åŒ', device='cpu')
print(result)
```
#### æ‰¹é‡æ–‡æœ¬ (batch without context)
```python
texts = ['ä½ çœŸè®¨åŒ', 'ä½ å¥½æ£’']
results = model.predict(texts, device='cpu')
print(results)
```
#### å¸¦ä¸Šä¸‹æ–‡çš„æ‰¹é‡æ–‡æœ¬ (batch with context)
```python
texts_with_context = [['ä½ çœŸè®¨åŒ', 'ä½ ä¸ºä»€ä¹ˆè¿™æ ·è¯´'], ['ä½ å¥½æ£’', 'è°¢è°¢ä½ çš„å¤¸å¥–']]
results = model.predict(texts_with_context, device='cpu')
print(results)
```

### 4. è¾“å‡ºæ ¼å¼ (Output format)
æ¯ä¸ªç»“æœä¸ºå­—å…¸ï¼ŒåŒ…å«ï¼š
- `text`: è¾“å…¥æ–‡æœ¬
- `prediction`: é¢„æµ‹ç±»åˆ«ï¼ˆ0=æ­£å¸¸ï¼Œ1=æœ‰å®³ï¼‰
- `probabilities`: æ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡

For more detailed information and data visualization, please refer to our paper (see assets/paper.pdf).
å¦‚éœ€å‚è€ƒæ›´è¯¦ç»†çš„ä»‹ç»ä»¥åŠæ›´å¤šæ•°æ®å¯è§†åŒ–ï¼Œè¯·å‚é˜…æˆ‘ä»¬çš„è®ºæ–‡ï¼ˆè§ assets/paper.pdfï¼‰ã€‚

---

## åœ¨çº¿ä½“éªŒ / Online Demo

ä½ å¯ä»¥åœ¨ HuggingFace Spaces å®˜æ–¹ç½‘ç«™ä¸Šåœ¨çº¿ä½“éªŒæœ¬é¡¹ç›®çš„æ¨ç†æ•ˆæœï¼š
[https://huggingface.co/spaces/Albert-CAC/lite_DETECTIVE](https://huggingface.co/spaces/Albert-CAC/lite_DETECTIVE)

You can try the official online demo here:
[https://huggingface.co/spaces/Albert-CAC/lite_DETECTIVE](https://huggingface.co/spaces/Albert-CAC/lite_DETECTIVE)

<div>
  <img src="assets/demo0.jpg" alt="åœ¨çº¿æ¨ç†æ¼”ç¤º Demo" width="600"/>
<p>1. **æˆ‘å–œæ¬¢ä½  - 96.63% (Positive)**<br>
   - Translation: I like you - 96.63% (Positive)<br>
   - Correctly identified as expressing positive sentiment.</p>

<p>2. **ä½ å¦ˆæ­»äº† - 97.82% (Negative)**<br>
   - Translation: Your mother is dead - 97.82% (Negative)<br>
   - Correctly identified as expressing negative sentiment.</p>

<p>3. **ä½ ğŸ´æ²¡äº† - 91.56% (Negative)**<br>
   - Translation: Your ğŸ´ is gone - 91.56% (Negative)<br>
   - Correctly identified as expressing negative sentiment. This might be unfamiliar to non-Chinese speakers, but it's a way of indirectly expressing a harsh sentiment.</p>

<p>4. **è‡­å‚»é€¼ - 98.68% (Negative)**<br>
   - Translation: You idiot - 98.68% (Negative)<br>
   - Correctly identified as expressing negative sentiment.</p>

<p>5. **ä»Šå¤©å¤©æ°”çœŸå¥½ - 97.89% (Positive)**<br>
   - Translation: The weather is great today - 97.89% (Positive)<br>
   - Correctly identified as expressing positive sentiment.</p>

<p>6. **ä½ å¥½æ£’ - 55.82% (Positive)**<br>
   - Translation: You're great - 55.82% (Positive)<br>
   - Correctly identified as expressing positive sentiment, although the confidence level is relatively low.</p>
<img src="assets/demo1.jpg" alt="åœ¨çº¿æ¨ç†æ¼”ç¤º Demo" width="600"/>
</div>

